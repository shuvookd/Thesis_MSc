{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install xgboost tensorflow pandas scikit-learn matplotlib seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T18:27:32.517142Z","iopub.execute_input":"2025-07-04T18:27:32.517428Z","iopub.status.idle":"2025-07-04T18:27:36.676208Z","shell.execute_reply.started":"2025-07-04T18:27:32.517406Z","shell.execute_reply":"2025-07-04T18:27:36.675285Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T18:27:57.932015Z","iopub.execute_input":"2025-07-04T18:27:57.932299Z","iopub.status.idle":"2025-07-04T18:28:13.003208Z","shell.execute_reply.started":"2025-07-04T18:27:57.932273Z","shell.execute_reply":"2025-07-04T18:28:13.002451Z"}},"outputs":[{"name":"stderr","text":"2025-07-04 18:27:59.788393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751653680.008068      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751653680.074051      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load parquet files (Kaggle-style)\ntrain = pd.read_parquet(\"/kaggle/input/unsw-nb15/UNSW_NB15_training-set.parquet\")\ntest = pd.read_parquet(\"/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.parquet\")\n\n# Combine and clean\ndf = pd.concat([train, test])\ndf = df.drop(columns=[\"id\", \"attack_cat\"], errors=\"ignore\")\n\n# Factorize categorical features\nfor col in ['proto', 'service', 'state']:\n    df[col] = pd.factorize(df[col])[0]\n\n# Extract X, y\nX = df.drop(columns=[\"label\"])\ny = df[\"label\"]\n\n# Standardize features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T18:35:34.072653Z","iopub.execute_input":"2025-07-04T18:35:34.073244Z","iopub.status.idle":"2025-07-04T18:35:34.385050Z","shell.execute_reply.started":"2025-07-04T18:35:34.073221Z","shell.execute_reply":"2025-07-04T18:35:34.384423Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def build_encoder(input_dim):\n    inputs = layers.Input(shape=(input_dim,))\n    x = layers.Dense(256)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('swish')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(128)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('swish')(x)\n    projection = layers.Dense(64)(x)\n    return models.Model(inputs, projection)\n\ndef contrastive_loss(query, key, queue, temperature=0.07):\n    query = tf.math.l2_normalize(query, axis=1)\n    key = tf.math.l2_normalize(key, axis=1)\n    queue = tf.math.l2_normalize(queue, axis=1)\n\n    l_pos = tf.reshape(tf.reduce_sum(query * key, axis=1), [-1, 1])\n    l_neg = tf.matmul(query, queue, transpose_b=True)\n    logits = tf.concat([l_pos, l_neg], axis=1) / temperature\n    labels = tf.zeros(logits.shape[0], dtype=tf.int32)\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits))\n\ndef augment_tabular(X, mask_prob=0.15, noise_std=0.05):\n    mask = (np.random.rand(*X.shape) > mask_prob).astype(np.float32)\n    noise = np.random.normal(0, noise_std, size=X.shape).astype(np.float32)\n    return X * mask + noise\n\n@tf.function\ndef momentum_update(query_encoder, key_encoder, m=0.999):\n    for q, k in zip(query_encoder.trainable_variables, key_encoder.trainable_variables):\n        k.assign(m * k + (1 - m) * q)\n\nclass MoCoQueue:\n    def __init__(self, dim=64, size=8192):\n        self.queue = tf.Variable(tf.random.normal([size, dim]), trainable=False)\n        self.queue.assign(tf.math.l2_normalize(self.queue, axis=1))\n        self.ptr = tf.Variable(0, trainable=False, dtype=tf.int32)\n        self.size = size\n\n    @tf.function\n    def enqueue(self, keys):\n        batch_size = tf.shape(keys)[0]\n        idx = tf.range(self.ptr, self.ptr + batch_size) % self.size\n        self.queue.scatter_nd_update(tf.expand_dims(idx, 1), keys)\n        self.ptr.assign((self.ptr + batch_size) % self.size)\n\n    def get(self):\n        return self.queue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T18:35:55.904532Z","iopub.execute_input":"2025-07-04T18:35:55.904849Z","iopub.status.idle":"2025-07-04T18:35:55.917295Z","shell.execute_reply.started":"2025-07-04T18:35:55.904823Z","shell.execute_reply":"2025-07-04T18:35:55.916436Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def run_moco_xgboost(X, y, ratios, epochs=20, batch_size=512):\n    results = []\n\n    combo_id = 1  # For Combo numbering like \"Combo 2\"\n\n    for train_pct, test_pct in ratios:\n        print(f\"\\n🔁 Combo {combo_id} → Train:Test = {train_pct}:{test_pct}\")\n        X_train, X_test, y_train, y_test = train_test_split(\n            X.astype(np.float32), y,\n            test_size=test_pct / 100, stratify=y, random_state=42\n        )\n\n        encoder = build_encoder(X_train.shape[1])\n        key_encoder = build_encoder(X_train.shape[1])\n        for q, k in zip(encoder.variables, key_encoder.variables):\n            k.assign(q)\n\n        optimizer = tf.keras.optimizers.Adam(3e-4)\n        queue = MoCoQueue()\n\n        last_loss = 0\n        last_report = {}\n\n        for epoch in range(epochs):\n            idx = np.random.permutation(X_train.shape[0])\n            X_shuffle = X_train[idx]\n\n            for i in range(0, len(X_shuffle), batch_size):\n                batch = X_shuffle[i:i + batch_size]\n                if batch.shape[0] < 2: continue\n                x_q = augment_tabular(batch)\n                x_k = augment_tabular(batch)\n\n                with tf.GradientTape() as tape:\n                    z_q = encoder(x_q, training=True)\n                    z_k = key_encoder(x_k, training=False)\n                    z_k = tf.stop_gradient(z_k)\n                    loss = contrastive_loss(z_q, z_k, queue.get())\n\n                grads = tape.gradient(loss, encoder.trainable_variables)\n                optimizer.apply_gradients(zip(grads, encoder.trainable_variables))\n                momentum_update(encoder, key_encoder)\n                queue.enqueue(z_k)\n\n            last_loss = float(loss.numpy())\n            print(f\" Epoch {epoch + 1}/{epochs}, Loss: {last_loss:.4f}\")\n\n        # Final evaluation after training\n        emb_train = encoder.predict(X_train)\n        emb_test = encoder.predict(X_test)\n\n        clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1,\n                                use_label_encoder=False, eval_metric='logloss')\n        clf.fit(emb_train, y_train)\n        y_pred = clf.predict(emb_test)\n\n        last_report = classification_report(y_test, y_pred, output_dict=True)\n\n        results.append({\n            'combo': combo_id,\n            'train_pct': train_pct,\n            'test_pct': test_pct,\n            'epoch': epochs,\n            'loss': last_loss,\n            'accuracy': last_report['accuracy'],\n            'f1_0': last_report['0']['f1-score'],\n            'f1_1': last_report['1']['f1-score']\n        })\n\n        # Final print after each combo\n        print(f\"{len(emb_test)}/{len(emb_test)} ━━━━━━━━━━━━━━━━━━━━ Done\")\n        print(f\"✅ Finished Combo {combo_id}: \"\n              f\"Accuracy={last_report['accuracy']:.4f}, \"\n              f\"Loss={last_loss:.4f}, \"\n              f\"F1 Class 0={last_report['0']['f1-score']:.4f}, \"\n              f\"F1 Class 1={last_report['1']['f1-score']:.4f}\")\n\n        combo_id += 1\n\n    return pd.DataFrame(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:02:23.775681Z","iopub.execute_input":"2025-07-04T19:02:23.775953Z","iopub.status.idle":"2025-07-04T19:02:23.786264Z","shell.execute_reply.started":"2025-07-04T19:02:23.775934Z","shell.execute_reply":"2025-07-04T19:02:23.785470Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"ratios = [(10, 90),(20, 80) ,(30, 70), (40, 60),(50, 50),(60, 40) ,(70, 30),(80, 20), (90, 10)]\nresults_df = run_moco_xgboost(X.values, y.values, ratios)\nresults_df.to_csv(\"moco_xgboost_results.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:02:34.875583Z","iopub.execute_input":"2025-07-04T19:02:34.875878Z","iopub.status.idle":"2025-07-04T20:13:21.781762Z","shell.execute_reply.started":"2025-07-04T19:02:34.875856Z","shell.execute_reply":"2025-07-04T20:13:21.781146Z"}},"outputs":[{"name":"stdout","text":"\n🔁 Combo 1 → Train:Test = 10:90\n Epoch 1/20, Loss: 6.4698\n Epoch 2/20, Loss: 6.1019\n Epoch 3/20, Loss: 6.0523\n Epoch 4/20, Loss: 6.0737\n Epoch 5/20, Loss: 5.8109\n Epoch 6/20, Loss: 6.0763\n Epoch 7/20, Loss: 6.0316\n Epoch 8/20, Loss: 5.9152\n Epoch 9/20, Loss: 5.8554\n Epoch 10/20, Loss: 5.9029\n Epoch 11/20, Loss: 5.8441\n Epoch 12/20, Loss: 5.8412\n Epoch 13/20, Loss: 5.7966\n Epoch 14/20, Loss: 5.8980\n Epoch 15/20, Loss: 5.6891\n Epoch 16/20, Loss: 5.4903\n Epoch 17/20, Loss: 5.7770\n Epoch 18/20, Loss: 5.6246\n Epoch 19/20, Loss: 5.8316\n Epoch 20/20, Loss: 5.4747\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n\u001b[1m7248/7248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n231906/231906 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 1: Accuracy=0.9057, Loss=5.4747, F1 Class 0=0.8635, F1 Class 1=0.9280\n\n🔁 Combo 2 → Train:Test = 20:80\n Epoch 1/20, Loss: 6.1185\n Epoch 2/20, Loss: 6.2035\n Epoch 3/20, Loss: 5.8014\n Epoch 4/20, Loss: 5.6785\n Epoch 5/20, Loss: 5.7990\n Epoch 6/20, Loss: 5.6457\n Epoch 7/20, Loss: 5.5883\n Epoch 8/20, Loss: 5.6989\n Epoch 9/20, Loss: 5.7281\n Epoch 10/20, Loss: 5.5005\n Epoch 11/20, Loss: 5.5681\n Epoch 12/20, Loss: 5.4211\n Epoch 13/20, Loss: 5.6680\n Epoch 14/20, Loss: 5.6388\n Epoch 15/20, Loss: 5.5231\n Epoch 16/20, Loss: 5.5012\n Epoch 17/20, Loss: 5.4534\n Epoch 18/20, Loss: 5.4147\n Epoch 19/20, Loss: 5.4438\n Epoch 20/20, Loss: 5.4332\n\u001b[1m1611/1611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m6442/6442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n206139/206139 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 2: Accuracy=0.9098, Loss=5.4332, F1 Class 0=0.8699, F1 Class 1=0.9309\n\n🔁 Combo 3 → Train:Test = 30:70\n Epoch 1/20, Loss: 6.0391\n Epoch 2/20, Loss: 5.8012\n Epoch 3/20, Loss: 5.8070\n Epoch 4/20, Loss: 5.7342\n Epoch 5/20, Loss: 5.6085\n Epoch 6/20, Loss: 5.6260\n Epoch 7/20, Loss: 5.6187\n Epoch 8/20, Loss: 5.5697\n Epoch 9/20, Loss: 5.5017\n Epoch 10/20, Loss: 5.5577\n Epoch 11/20, Loss: 5.5824\n Epoch 12/20, Loss: 5.4662\n Epoch 13/20, Loss: 5.4508\n Epoch 14/20, Loss: 5.4151\n Epoch 15/20, Loss: 5.5214\n Epoch 16/20, Loss: 5.3388\n Epoch 17/20, Loss: 5.3397\n Epoch 18/20, Loss: 5.2876\n Epoch 19/20, Loss: 5.3362\n Epoch 20/20, Loss: 5.2586\n\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n\u001b[1m5637/5637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n180372/180372 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 3: Accuracy=0.9113, Loss=5.2586, F1 Class 0=0.8721, F1 Class 1=0.9322\n\n🔁 Combo 4 → Train:Test = 40:60\n Epoch 1/20, Loss: 5.8824\n Epoch 2/20, Loss: 5.7135\n Epoch 3/20, Loss: 5.9564\n Epoch 4/20, Loss: 5.5902\n Epoch 5/20, Loss: 5.6442\n Epoch 6/20, Loss: 5.5652\n Epoch 7/20, Loss: 5.5793\n Epoch 8/20, Loss: 5.4060\n Epoch 9/20, Loss: 5.4490\n Epoch 10/20, Loss: 5.2737\n Epoch 11/20, Loss: 5.4047\n Epoch 12/20, Loss: 5.4153\n Epoch 13/20, Loss: 5.5538\n Epoch 14/20, Loss: 5.3930\n Epoch 15/20, Loss: 5.4044\n Epoch 16/20, Loss: 5.4606\n Epoch 17/20, Loss: 5.2165\n Epoch 18/20, Loss: 5.3343\n Epoch 19/20, Loss: 5.4217\n Epoch 20/20, Loss: 5.6170\n\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n\u001b[1m4832/4832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n154604/154604 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 4: Accuracy=0.9122, Loss=5.6170, F1 Class 0=0.8732, F1 Class 1=0.9328\n\n🔁 Combo 5 → Train:Test = 50:50\n Epoch 1/20, Loss: 5.8057\n Epoch 2/20, Loss: 5.4944\n Epoch 3/20, Loss: 5.5553\n Epoch 4/20, Loss: 5.5830\n Epoch 5/20, Loss: 5.6467\n Epoch 6/20, Loss: 5.5240\n Epoch 7/20, Loss: 5.5310\n Epoch 8/20, Loss: 5.3507\n Epoch 9/20, Loss: 5.4614\n Epoch 10/20, Loss: 5.2781\n Epoch 11/20, Loss: 5.5828\n Epoch 12/20, Loss: 5.2825\n Epoch 13/20, Loss: 5.6132\n Epoch 14/20, Loss: 5.4340\n Epoch 15/20, Loss: 5.2205\n Epoch 16/20, Loss: 5.5540\n Epoch 17/20, Loss: 5.3969\n Epoch 18/20, Loss: 5.2990\n Epoch 19/20, Loss: 5.3348\n Epoch 20/20, Loss: 5.3425\n\u001b[1m4027/4027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n\u001b[1m4027/4027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n128837/128837 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 5: Accuracy=0.9112, Loss=5.3425, F1 Class 0=0.8713, F1 Class 1=0.9322\n\n🔁 Combo 6 → Train:Test = 60:40\n Epoch 1/20, Loss: 5.8321\n Epoch 2/20, Loss: 5.7753\n Epoch 3/20, Loss: 5.6217\n Epoch 4/20, Loss: 5.5631\n Epoch 5/20, Loss: 5.5859\n Epoch 6/20, Loss: 5.5574\n Epoch 7/20, Loss: 5.5305\n Epoch 8/20, Loss: 5.3796\n Epoch 9/20, Loss: 5.3517\n Epoch 10/20, Loss: 5.2667\n Epoch 11/20, Loss: 5.2431\n Epoch 12/20, Loss: 5.3221\n Epoch 13/20, Loss: 5.3702\n Epoch 14/20, Loss: 5.3212\n Epoch 15/20, Loss: 5.3280\n Epoch 16/20, Loss: 5.3929\n Epoch 17/20, Loss: 5.4259\n Epoch 18/20, Loss: 5.3676\n Epoch 19/20, Loss: 5.3950\n Epoch 20/20, Loss: 5.3755\n\u001b[1m4832/4832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n103070/103070 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 6: Accuracy=0.9135, Loss=5.3755, F1 Class 0=0.8759, F1 Class 1=0.9336\n\n🔁 Combo 7 → Train:Test = 70:30\n Epoch 1/20, Loss: 5.9645\n Epoch 2/20, Loss: 5.8251\n Epoch 3/20, Loss: 5.5804\n Epoch 4/20, Loss: 5.3629\n Epoch 5/20, Loss: 5.7011\n Epoch 6/20, Loss: 5.1669\n Epoch 7/20, Loss: 5.2768\n Epoch 8/20, Loss: 5.2749\n Epoch 9/20, Loss: 5.1963\n Epoch 10/20, Loss: 5.4135\n Epoch 11/20, Loss: 5.1217\n Epoch 12/20, Loss: 5.5790\n Epoch 13/20, Loss: 5.2822\n Epoch 14/20, Loss: 5.6835\n Epoch 15/20, Loss: 5.7450\n Epoch 16/20, Loss: 5.4987\n Epoch 17/20, Loss: 5.4620\n Epoch 18/20, Loss: 5.3710\n Epoch 19/20, Loss: 5.6745\n Epoch 20/20, Loss: 5.4033\n\u001b[1m5637/5637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n77302/77302 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 7: Accuracy=0.9120, Loss=5.4033, F1 Class 0=0.8730, F1 Class 1=0.9327\n\n🔁 Combo 8 → Train:Test = 80:20\n Epoch 1/20, Loss: 5.8686\n Epoch 2/20, Loss: 5.6650\n Epoch 3/20, Loss: 5.5512\n Epoch 4/20, Loss: 5.3759\n Epoch 5/20, Loss: 5.5163\n Epoch 6/20, Loss: 5.3583\n Epoch 7/20, Loss: 5.3663\n Epoch 8/20, Loss: 5.1420\n Epoch 9/20, Loss: 5.2744\n Epoch 10/20, Loss: 5.5346\n Epoch 11/20, Loss: 5.4095\n Epoch 12/20, Loss: 5.2848\n Epoch 13/20, Loss: 5.3220\n Epoch 14/20, Loss: 5.3866\n Epoch 15/20, Loss: 5.4318\n Epoch 16/20, Loss: 5.5018\n Epoch 17/20, Loss: 5.4921\n Epoch 18/20, Loss: 5.7110\n Epoch 19/20, Loss: 5.5715\n Epoch 20/20, Loss: 5.4711\n\u001b[1m6442/6442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n\u001b[1m1611/1611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n51535/51535 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 8: Accuracy=0.9114, Loss=5.4711, F1 Class 0=0.8729, F1 Class 1=0.9320\n\n🔁 Combo 9 → Train:Test = 90:10\n Epoch 1/20, Loss: 5.8244\n Epoch 2/20, Loss: 5.6043\n Epoch 3/20, Loss: 5.4859\n Epoch 4/20, Loss: 5.4113\n Epoch 5/20, Loss: 5.4765\n Epoch 6/20, Loss: 5.3601\n Epoch 7/20, Loss: 5.4766\n Epoch 8/20, Loss: 5.4145\n Epoch 9/20, Loss: 5.5081\n Epoch 10/20, Loss: 5.4882\n Epoch 11/20, Loss: 5.5167\n Epoch 12/20, Loss: 5.4254\n Epoch 13/20, Loss: 5.4197\n Epoch 14/20, Loss: 5.4272\n Epoch 15/20, Loss: 5.3922\n Epoch 16/20, Loss: 5.5194\n Epoch 17/20, Loss: 5.3227\n Epoch 18/20, Loss: 5.3627\n Epoch 19/20, Loss: 5.3353\n Epoch 20/20, Loss: 5.3860\n\u001b[1m7248/7248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n\u001b[1m806/806\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n25768/25768 ━━━━━━━━━━━━━━━━━━━━ Done\n✅ Finished Combo 9: Accuracy=0.9090, Loss=5.3860, F1 Class 0=0.8678, F1 Class 1=0.9306\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nsns.lineplot(data=results_df, x=\"epoch\", y=\"accuracy\", hue=\"train_pct\", marker=\"o\")\nplt.title(\"Accuracy vs Epoch for Each Train Ratio\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(title=\"Train %\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T21:46:57.577237Z","iopub.execute_input":"2025-07-04T21:46:57.577396Z","iopub.status.idle":"2025-07-04T21:46:57.671918Z","shell.execute_reply.started":"2025-07-04T21:46:57.577381Z","shell.execute_reply":"2025-07-04T21:46:57.670791Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1701471541.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_pct\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"o\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy vs Epoch for Each Train Ratio\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"avg_scores = results_df.groupby(\"train_pct\")[[\"f1_0\", \"f1_1\"]].mean().reset_index()\navg_scores = pd.melt(avg_scores, id_vars=\"train_pct\", var_name=\"Class\", value_name=\"F1-Score\")\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=avg_scores, x=\"train_pct\", y=\"F1-Score\", hue=\"Class\")\nplt.title(\"Average F1-Score by Train Ratio and Class\")\nplt.xlabel(\"Train %\")\nplt.ylabel(\"F1-Score\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_acc = results_df.groupby(\"train_pct\")[\"accuracy\"].max().reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=best_acc, x=\"train_pct\", y=\"accuracy\", palette=\"viridis\")\nplt.title(\"Best Accuracy per Train %\")\nplt.xlabel(\"Train %\")\nplt.ylabel(\"Best Accuracy\")\nplt.ylim(0.5, 1.0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}