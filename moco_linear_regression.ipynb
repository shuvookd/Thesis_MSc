{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgofqcl8N9P9TMg72x8BWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvookd/Thesis_MSc/blob/main/moco_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5toQn2vhgFfW",
        "outputId": "f131d3e1-bc51-4eb6-f27e-5bcdc90b4b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Combo 1 ‚Üí Train:Test = 10:90\n",
            " Epoch 1/20, Loss: 6.5520\n",
            " Epoch 2/20, Loss: 6.1999\n",
            " Epoch 3/20, Loss: 6.0399\n",
            " Epoch 4/20, Loss: 6.0731\n",
            " Epoch 5/20, Loss: 6.0904\n",
            " Epoch 6/20, Loss: 5.9183\n",
            " Epoch 7/20, Loss: 6.0716\n",
            " Epoch 8/20, Loss: 6.0081\n",
            " Epoch 9/20, Loss: 5.8959\n",
            " Epoch 10/20, Loss: 5.7670\n",
            " Epoch 11/20, Loss: 5.8386\n",
            " Epoch 12/20, Loss: 5.8900\n",
            " Epoch 13/20, Loss: 5.5774\n",
            " Epoch 14/20, Loss: 5.6856\n",
            " Epoch 15/20, Loss: 5.7271\n",
            " Epoch 16/20, Loss: 5.8022\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------------------\n",
        "# Load and Prepare Data\n",
        "# -------------------------------\n",
        "train = pd.read_parquet(\"/content/UNSW_NB15_training-set.parquet\")\n",
        "test = pd.read_parquet(\"/content/UNSW_NB15_testing-set.parquet\")\n",
        "\n",
        "df = pd.concat([train, test])\n",
        "df = df.drop(columns=[\"id\", \"attack_cat\"], errors=\"ignore\")\n",
        "\n",
        "for col in ['proto', 'service', 'state']:\n",
        "    df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# -------------------------------\n",
        "# MoCo Model Components\n",
        "# -------------------------------\n",
        "def build_encoder(input_dim):\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(256)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('swish')(x)\n",
        "    projection = layers.Dense(64)(x)\n",
        "    return models.Model(inputs, projection)\n",
        "\n",
        "def contrastive_loss(query, key, queue, temperature=0.07):\n",
        "    query = tf.math.l2_normalize(query, axis=1)\n",
        "    key = tf.math.l2_normalize(key, axis=1)\n",
        "    queue = tf.math.l2_normalize(queue, axis=1)\n",
        "    l_pos = tf.reshape(tf.reduce_sum(query * key, axis=1), [-1, 1])\n",
        "    l_neg = tf.matmul(query, queue, transpose_b=True)\n",
        "    logits = tf.concat([l_pos, l_neg], axis=1) / temperature\n",
        "    labels = tf.zeros(logits.shape[0], dtype=tf.int32)\n",
        "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits))\n",
        "\n",
        "def augment_tabular(X, mask_prob=0.15, noise_std=0.05):\n",
        "    mask = (np.random.rand(*X.shape) > mask_prob).astype(np.float32)\n",
        "    noise = np.random.normal(0, noise_std, size=X.shape).astype(np.float32)\n",
        "    return X * mask + noise\n",
        "\n",
        "@tf.function\n",
        "def momentum_update(query_encoder, key_encoder, m=0.999):\n",
        "    for q, k in zip(query_encoder.trainable_variables, key_encoder.trainable_variables):\n",
        "        k.assign(m * k + (1 - m) * q)\n",
        "\n",
        "class MoCoQueue:\n",
        "    def __init__(self, dim=64, size=8192):\n",
        "        self.queue = tf.Variable(tf.random.normal([size, dim]), trainable=False)\n",
        "        self.queue.assign(tf.math.l2_normalize(self.queue, axis=1))\n",
        "        self.ptr = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
        "        self.size = size\n",
        "\n",
        "    @tf.function\n",
        "    def enqueue(self, keys):\n",
        "        batch_size = tf.shape(keys)[0]\n",
        "        idx = tf.range(self.ptr, self.ptr + batch_size) % self.size\n",
        "        self.queue.scatter_nd_update(tf.expand_dims(idx, 1), keys)\n",
        "        self.ptr.assign((self.ptr + batch_size) % self.size)\n",
        "\n",
        "    def get(self):\n",
        "        return self.queue\n",
        "\n",
        "# -------------------------------\n",
        "# Run MoCo + Logistic Regression\n",
        "# -------------------------------\n",
        "def run_moco_logreg(X, y, ratios, epochs=20, batch_size=512):\n",
        "    results = []\n",
        "    combo_id = 1\n",
        "\n",
        "    for train_pct, test_pct in ratios:\n",
        "        print(f\"\\nüîÅ Combo {combo_id} ‚Üí Train:Test = {train_pct}:{test_pct}\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X.astype(np.float32), y,\n",
        "            test_size=test_pct / 100, stratify=y, random_state=42\n",
        "        )\n",
        "\n",
        "        encoder = build_encoder(X_train.shape[1])\n",
        "        key_encoder = build_encoder(X_train.shape[1])\n",
        "        for q, k in zip(encoder.variables, key_encoder.variables):\n",
        "            k.assign(q)\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(3e-4)\n",
        "        queue = MoCoQueue()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            idx = np.random.permutation(X_train.shape[0])\n",
        "            X_shuffle = X_train[idx]\n",
        "\n",
        "            for i in range(0, len(X_shuffle), batch_size):\n",
        "                batch = X_shuffle[i:i + batch_size]\n",
        "                if batch.shape[0] < 2: continue\n",
        "                x_q = augment_tabular(batch)\n",
        "                x_k = augment_tabular(batch)\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    z_q = encoder(x_q, training=True)\n",
        "                    z_k = key_encoder(x_k, training=False)\n",
        "                    z_k = tf.stop_gradient(z_k)\n",
        "                    loss = contrastive_loss(z_q, z_k, queue.get())\n",
        "\n",
        "                grads = tape.gradient(loss, encoder.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, encoder.trainable_variables))\n",
        "                momentum_update(encoder, key_encoder)\n",
        "                queue.enqueue(z_k)\n",
        "\n",
        "            print(f\" Epoch {epoch + 1}/{epochs}, Loss: {float(loss):.4f}\")\n",
        "\n",
        "        emb_train = encoder.predict(X_train)\n",
        "        emb_test = encoder.predict(X_test)\n",
        "\n",
        "        clf = LogisticRegression(max_iter=1000)\n",
        "        clf.fit(emb_train, y_train)\n",
        "        y_pred = clf.predict(emb_test)\n",
        "\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        results.append({\n",
        "            'combo': combo_id,\n",
        "            'train_pct': train_pct,\n",
        "            'test_pct': test_pct,\n",
        "            'epoch': epochs,\n",
        "            'loss': float(loss),\n",
        "            'accuracy': report['accuracy'],\n",
        "            'f1_0': report['0']['f1-score'],\n",
        "            'f1_1': report['1']['f1-score']\n",
        "        })\n",
        "\n",
        "        print(f\"‚úÖ Finished Combo {combo_id}: \"\n",
        "              f\"Accuracy={report['accuracy']:.4f}, \"\n",
        "              f\"F1 Class 0={report['0']['f1-score']:.4f}, \"\n",
        "              f\"F1 Class 1={report['1']['f1-score']:.4f}\")\n",
        "        combo_id += 1\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# -------------------------------\n",
        "# Train + Save + Visualize\n",
        "# -------------------------------\n",
        "ratios = [(10, 90), (20, 80), (30, 70), (40, 60), (50, 50), (60, 40), (70, 30), (80, 20), (90, 10)]\n",
        "results_df = run_moco_logreg(X.values, y.values, ratios)\n",
        "results_df.to_csv(\"moco_logreg_results.csv\", index=False)\n",
        "\n",
        "# Accuracy vs Epoch Plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.lineplot(data=results_df, x=\"epoch\", y=\"accuracy\", hue=\"train_pct\", marker=\"o\")\n",
        "plt.title(\"Accuracy vs Epoch for Each Train Ratio (Logistic Regression)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(title=\"Train %\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Average F1 Score Plot\n",
        "avg_scores = results_df.groupby(\"train_pct\")[[\"f1_0\", \"f1_1\"]].mean().reset_index()\n",
        "avg_scores = pd.melt(avg_scores, id_vars=\"train_pct\", var_name=\"Class\", value_name=\"F1-Score\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=avg_scores, x=\"train_pct\", y=\"F1-Score\", hue=\"Class\")\n",
        "plt.title(\"Average F1-Score by Train Ratio and Class (Logistic Regression)\")\n",
        "plt.xlabel(\"Train %\")\n",
        "plt.ylabel(\"F1-Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Best Accuracy Plot\n",
        "best_acc = results_df.groupby(\"train_pct\")[\"accuracy\"].max().reset_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=best_acc, x=\"train_pct\", y=\"accuracy\", palette=\"viridis\")\n",
        "plt.title(\"Best Accuracy per Train % (Logistic Regression)\")\n",
        "plt.xlabel(\"Train %\")\n",
        "plt.ylabel(\"Best Accuracy\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}